{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc268cb-99b6-43a2-9c6a-c1463291ee3a",
   "metadata": {
    "collapsed": false,
    "name": "Overview"
   },
   "source": [
    "# Building My Agentic AI Application In Snowflake\n",
    "\n",
    "### *NOTE: For overview, prerequisites and other instructions, refer to this [guide](https://github.com/Snowflake-Labs/sfguide-build-data-agents-using-snowflake-cortex-ai).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Import_libraries"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ccdefe-a821-4385-adf0-8747add404a8",
   "metadata": {
    "collapsed": false,
    "name": "Setup_tools"
   },
   "source": [
    "## Setup Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554b86d-68eb-4aff-a554-c80f26136f39",
   "metadata": {
    "collapsed": false,
    "name": "Unstructured_data"
   },
   "source": [
    "### Cortex Search: Tool for Unstructured Data\n",
    "\n",
    "Setup a tool that will help the agent to extract information from unstructured data. It will process PDF documents about bikes and skis, and also use image descriptions. The information is stored in PDF and JPEG format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03547828-0533-4716-99ad-a97b54459178",
   "metadata": {
    "collapsed": false,
    "name": "PDFs"
   },
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "Preview_pdfs"
   },
   "outputs": [],
   "source": [
    "-- Preview documents\n",
    "SELECT * FROM DIRECTORY('@DOCS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b90d93-69b4-4d6e-b9da-91afd1a2fddc",
   "metadata": {
    "collapsed": false,
    "name": "Parse"
   },
   "source": [
    "Read/process the PDF files using SNOWFLAKE.CORTEX.PARSE_DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "Parse_docs"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TEMPORARY TABLE RAW_TEXT AS\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    TO_VARCHAR (\n",
    "        SNOWFLAKE.CORTEX.PARSE_DOCUMENT (\n",
    "            '@DOCS',\n",
    "            RELATIVE_PATH,\n",
    "            {'mode': 'LAYOUT'} ):content\n",
    "        ) AS EXTRACTED_LAYOUT \n",
    "FROM \n",
    "    DIRECTORY('@DOCS')\n",
    "WHERE\n",
    "    RELATIVE_PATH LIKE '%.pdf';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621c481-9b70-4d45-89f8-2d6d9e60827d",
   "metadata": {
    "language": "sql",
    "name": "Preview_parsed_docs"
   },
   "outputs": [],
   "source": [
    "select * from RAW_TEXT limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132582de-f23d-4f51-bbf9-44674d30592c",
   "metadata": {
    "collapsed": false,
    "name": "Docs_chunks"
   },
   "source": [
    "Create the table that will be used by Cortex Search service as a tool for Cortex Agents in order to retrieve information from PDF and JPEG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17281011-347a-4333-86df-b2689a85a221",
   "metadata": {
    "language": "sql",
    "name": "Create_docs_chunks"
   },
   "outputs": [],
   "source": [
    "create or replace TABLE DOCS_CHUNKS_TABLE ( \n",
    "    RELATIVE_PATH VARCHAR(16777216), -- Relative path to the PDF file\n",
    "    CHUNK VARCHAR(16777216), -- Piece of text\n",
    "    CHUNK_INDEX INTEGER, -- Index for the text\n",
    "    CATEGORY VARCHAR(16777216) -- Will hold the document category to enable filtering\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040e105-5e88-4525-8eb1-a92fb40bf4a2",
   "metadata": {
    "language": "sql",
    "name": "Split_docs"
   },
   "outputs": [],
   "source": [
    "insert into DOCS_CHUNKS_TABLE (relative_path, chunk, chunk_index)\n",
    "\n",
    "    select relative_path, \n",
    "            c.value::TEXT as chunk,\n",
    "            c.INDEX::INTEGER as chunk_index\n",
    "            \n",
    "    from \n",
    "        raw_text,\n",
    "        LATERAL FLATTEN( input => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (\n",
    "              EXTRACTED_LAYOUT,\n",
    "              'markdown',\n",
    "              1512,\n",
    "              256,\n",
    "              ['\\n\\n', '\\n', ' ', '']\n",
    "           )) c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183043db-6148-4409-8bac-b1112d1b93d2",
   "metadata": {
    "language": "sql",
    "name": "Preview_docs_chunks"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DOCS_CHUNKS_TABLE limit 7;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76428176-e27a-4a02-8439-024a09fd3d55",
   "metadata": {
    "collapsed": false,
    "name": "Classify"
   },
   "source": [
    "Let's see how CLASSIFY_TEXT Cortex function can be used to classify the document type. We have two classes, Bike and Snow, and we pass the document title and the first chunk of the document to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe24f7-4486-4d2a-b342-7dda8bce59ef",
   "metadata": {
    "language": "sql",
    "name": "Classify_docs"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TEMPORARY TABLE docs_categories AS WITH unique_documents AS (\n",
    "  SELECT\n",
    "    DISTINCT relative_path, chunk\n",
    "  FROM\n",
    "    docs_chunks_table\n",
    "  WHERE \n",
    "    chunk_index = 0\n",
    "  ),\n",
    " docs_category_cte AS (\n",
    "  SELECT\n",
    "    relative_path,\n",
    "    TRIM(snowflake.cortex.CLASSIFY_TEXT (\n",
    "      'Title:' || relative_path || 'Content:' || chunk, ['Bike', 'Snow']\n",
    "     )['label'], '\"') AS category\n",
    "  FROM\n",
    "    unique_documents\n",
    ")\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  docs_category_cte;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563deac8-2b50-4c0c-a712-f14eac57e094",
   "metadata": {
    "language": "sql",
    "name": "Preview_classification"
   },
   "outputs": [],
   "source": [
    "select * from docs_categories;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3cc3b6-8471-4af0-b562-67e6174eb565",
   "metadata": {
    "language": "sql",
    "name": "Update_docs_chunks"
   },
   "outputs": [],
   "source": [
    "update docs_chunks_table \n",
    "  SET category = docs_categories.category\n",
    "  from docs_categories\n",
    "  where  docs_chunks_table.relative_path = docs_categories.relative_path;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352527e8-4b98-4c08-8c01-c3758a9ca91e",
   "metadata": {
    "collapsed": false,
    "name": "Images"
   },
   "source": [
    "### Images\n",
    "\n",
    "Now let's process the images we have for our bikes and skis. We are going to use COMPLETE multi-modal function to generate image descriptions and classifications. We will add this information to the DOCS_CHUNKS_TABLE where we also have the PDF documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe08185-7dc3-4227-b2f1-f6ee1697d714",
   "metadata": {
    "language": "sql",
    "name": "Image_classification"
   },
   "outputs": [],
   "source": [
    "insert into DOCS_CHUNKS_TABLE (relative_path, chunk, chunk_index, category)\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    CONCAT('This is a picture describing the bike or ski: '|| RELATIVE_PATH || \n",
    "        'THIS IS THE DESCRIPTION: ' ||\n",
    "        SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet',\n",
    "        'DESCRIBE THIS IMAGE: ',\n",
    "        TO_FILE('@DOCS', RELATIVE_PATH))) as chunk,\n",
    "    0,\n",
    "    SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet',\n",
    "        'Classify this image, respond only with Bike or Snow: ',\n",
    "        TO_FILE('@DOCS', RELATIVE_PATH)) as category,\n",
    "FROM \n",
    "    DIRECTORY('@DOCS')\n",
    "WHERE\n",
    "    RELATIVE_PATH LIKE '%.jpeg';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206862d8-ea66-456b-a297-b4750cd02971",
   "metadata": {
    "language": "sql",
    "name": "Preview_updated_chunks"
   },
   "outputs": [],
   "source": [
    "select * from DOCS_CHUNKS_TABLE\n",
    "    where RELATIVE_PATH LIKE '%.jpeg';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1505035-726b-4447-b182-84a3707f015d",
   "metadata": {
    "collapsed": false,
    "name": "Cortex_Search"
   },
   "source": [
    "### Cortex Search\n",
    "\n",
    "Cortex Search tool will be used to retrieve context from unstructured data. Once we have processed all the content from PDFs and images into the DOCS_CHUNK_TABLE, we just need to enable the service in that table. This will automatically create the embeddings, indexing, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77174449-fc9c-4551-9563-5f10930a5aa2",
   "metadata": {
    "language": "sql",
    "name": "Create_search_service"
   },
   "outputs": [],
   "source": [
    "create or replace CORTEX SEARCH SERVICE DOCUMENTATION_TOOL\n",
    "ON chunk\n",
    "ATTRIBUTES relative_path, category\n",
    "warehouse = COMPUTE_WH\n",
    "TARGET_LAG = '1 hour'\n",
    "EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "as (\n",
    "    select chunk,\n",
    "        chunk_index,\n",
    "        relative_path,\n",
    "        category\n",
    "    from docs_chunks_table\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92e083-2415-4c42-aa87-80187831c8bb",
   "metadata": {
    "collapsed": false,
    "name": "Structured_data"
   },
   "source": [
    "### Cortex Analyst: Tool for Structured Data\n",
    "\n",
    "Another tool that we will setup is Cortex Analyst. It will provide the capability to extract information from structured data stored in Snowflake tables. In the API call we will provider the location of our semantic file that contains information about the business terminology used to describe the data.\n",
    "\n",
    "First, let's create some tables and generate data that provides additional context about Robot results.\n",
    "\n",
    "**ROBOT_RESULTS â€“ Structural Analysis Results Table**\n",
    "\n",
    "**Purpose:**  \n",
    "Stores stress results for structural members as exported from Autodesk Robot Structural Analysis.  \n",
    "This data helps engineers evaluate structural performance under different load cases.\n",
    "\n",
    "**Key Columns:**\n",
    "\n",
    "- MEMBER_NODE_CASE (Primary Key): Combined string identifying the member number, node number, and load case (e.g. `1/194/100 (C)`).\n",
    "- S_MAX_MPA: Maximum stress value in MPa.\n",
    "- S_MIN_MPA: Minimum stress value in MPa.\n",
    "- S_MAX_MY_MPA: Maximum bending stress about the local y-axis in MPa.\n",
    "- S_MAX_MZ_MPA: Maximum bending stress about the local z-axis in MPa.\n",
    "- S_MIN_MY_MPA: Minimum bending stress about the local y-axis in MPa.\n",
    "- S_MIN_MZ_MPA: Minimum bending stress about the local z-axis in MPa.\n",
    "- FX_AX_MPA: Axial stress in MPa.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94632a62-3b94-4d3a-9b1e-98aee4da1ac6",
   "metadata": {
    "language": "sql",
    "name": "Create_article_table"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "-- Create table for structural analysis results\n",
    "CREATE OR REPLACE TABLE DIM_STRUCTURAL_ANALYSIS (\n",
    "    ANALYSIS_ID INT AUTOINCREMENT PRIMARY KEY,\n",
    "    MEMBER_ID INT,\n",
    "    NODE_ID INT,\n",
    "    CASE_ID STRING,\n",
    "    CASE_TYPE STRING, -- 'BASIC' or 'COMBINATION' (for cases with 'C' suffix)\n",
    "    S_MAX_MPA FLOAT,\n",
    "    S_MIN_MPA FLOAT,\n",
    "    S_MAX_MY_MPA FLOAT,\n",
    "    S_MAX_MZ_MPA FLOAT,\n",
    "    S_MIN_MY_MPA FLOAT,\n",
    "    S_MIN_MZ_MPA FLOAT,\n",
    "    FX_AX_MPA FLOAT,\n",
    "    MEMBER_NODE_CASE STRING -- Original identifier for reference\n",
    ");\n",
    "\n",
    "-- Insert sample data from your structural analysis\n",
    "INSERT INTO DIM_STRUCTURAL_ANALYSIS (\n",
    "    MEMBER_ID, NODE_ID, CASE_ID, CASE_TYPE, S_MAX_MPA, S_MIN_MPA, \n",
    "    S_MAX_MY_MPA, S_MAX_MZ_MPA, S_MIN_MY_MPA, S_MIN_MZ_MPA, \n",
    "    FX_AX_MPA, MEMBER_NODE_CASE\n",
    ") VALUES \n",
    "-- Member 1, Node 194 cases\n",
    "(1, 194, '1', 'BASIC', 4.87, -10.39, 5.88, 0.86, -5.88, -2.64, -1.87, '1/194/1'),\n",
    "(1, 194, '2', 'BASIC', 0.02, -0.05, 0.03, 0.00, -0.03, -0.02, -0.01, '1/194/2'),\n",
    "(1, 194, '3', 'BASIC', 0.09, -0.07, 0.07, 0.01, -0.07, -0.02, 0.02, '1/194/3'),\n",
    "(1, 194, '10', 'BASIC', 0.03, -0.02, 0.02, 0.00, -0.02, -0.00, 0.00, '1/194/10'),\n",
    "(1, 194, '11', 'BASIC', 1.58, -4.27, 2.52, 0.20, -2.52, -0.62, -1.13, '1/194/11'),\n",
    "(1, 194, '12', 'BASIC', 4.71, -1.08, 2.45, 0.67, -2.45, -0.22, 1.59, '1/194/12'),\n",
    "(1, 194, '13', 'BASIC', 2.00, -0.64, 0.25, 1.61, -0.25, -0.52, 0.14, '1/194/13'),\n",
    "(1, 194, '14', 'BASIC', 0.45, -1.57, 0.26, 0.37, -0.26, -1.13, -0.18, '1/194/14'),\n",
    "(1, 194, '100', 'COMBINATION', 9.14, -20.61, 11.88, 1.47, -11.88, -4.52, -4.21, '1/194/100 (C)'),\n",
    "(1, 194, '101', 'COMBINATION', 5.14, -7.14, 4.42, 0.84, -4.42, -2.59, -0.13, '1/194/101 (C)'),\n",
    "(1, 194, '102', 'COMBINATION', 6.58, -11.97, 8.49, 0.38, -8.49, -1.18, -2.30, '1/194/102 (C)'),\n",
    "(1, 194, '103', 'COMBINATION', 6.65, -15.77, 7.71, 1.72, -7.71, -5.29, -2.78, '1/194/103 (C)'),\n",
    "(1, 194, '200', 'COMBINATION', 6.59, -14.79, 8.52, 1.07, -8.52, -3.28, -2.99, '1/194/200 (C)'),\n",
    "(1, 194, '201', 'COMBINATION', 3.92, -5.81, 3.55, 0.65, -3.55, -1.99, -0.27, '1/194/201 (C)'),\n",
    "(1, 194, '202', 'COMBINATION', 4.88, -9.03, 6.26, 0.34, -6.26, -1.06, -1.72, '1/194/202 (C)'),\n",
    "(1, 194, '203', 'COMBINATION', 4.93, -11.57, 5.74, 1.23, -5.74, -3.79, -2.04, '1/194/203 (C)'),\n",
    "(1, 194, '1000', 'BASIC', 6.58, -14.02, 7.94, 1.16, -7.94, -3.56, -2.52, '1/194/1000'),\n",
    "\n",
    "-- Member 1, Node 347 cases\n",
    "(1, 347, '1', 'BASIC', 3.73, -4.32, 3.33, 1.05, -3.33, -0.34, -0.65, '1/347/1'),\n",
    "(1, 347, '2', 'BASIC', -0.05, -0.08, 0.01, 0.00, -0.01, -0.01, -0.06, '1/347/2'),\n",
    "(1, 347, '3', 'BASIC', 0.04, 0.01, 0.01, 0.01, -0.01, -0.00, 0.02, '1/347/3'),\n",
    "(1, 347, '10', 'BASIC', 0.02, -0.01, 0.01, 0.01, -0.01, -0.00, 0.01, '1/347/10'),\n",
    "(1, 347, '11', 'BASIC', -0.62, -0.82, 0.04, 0.03, -0.04, -0.08, -0.69, '1/347/11'),\n",
    "(1, 347, '12', 'BASIC', 1.17, 0.90, 0.06, 0.10, -0.06, -0.03, 1.00, '1/347/12'),\n",
    "(1, 347, '13', 'BASIC', 0.25, -0.47, 0.27, 0.04, -0.27, -0.14, -0.07, '1/347/13'),\n",
    "(1, 347, '14', 'BASIC', 0.34, -0.32, 0.26, 0.11, -0.26, -0.03, -0.02, '1/347/14'),\n",
    "(1, 347, '100', 'COMBINATION', 3.82, -6.85, 4.47, 1.30, -4.47, -0.42, -1.95, '1/347/100 (C)'),\n",
    "(1, 347, '101', 'COMBINATION', 6.79, -4.56, 4.64, 1.57, -4.64, -0.51, 0.58, '1/347/101 (C)'),\n",
    "(1, 347, '102', 'COMBINATION', 4.33, -5.54, 4.14, 1.21, -4.14, -0.39, -1.01, '1/347/102 (C)'),\n",
    "(1, 347, '103', 'COMBINATION', 5.55, -6.40, 4.93, 1.57, -4.93, -0.51, -0.95, '1/347/103 (C)'),\n",
    "(1, 347, '200', 'COMBINATION', 2.92, -5.00, 3.32, 0.97, -3.32, -0.32, -1.37, '1/347/200 (C)'),\n",
    "(1, 347, '201', 'COMBINATION', 4.90, -3.48, 3.43, 1.15, -3.43, -0.37, 0.32, '1/347/201 (C)'),\n",
    "(1, 347, '202', 'COMBINATION', 3.26, -4.13, 3.09, 0.91, -3.09, -0.30, -0.74, '1/347/202 (C)'),\n",
    "(1, 347, '203', 'COMBINATION', 4.07, -4.70, 3.62, 1.15, -3.62, -0.37, -0.70, '1/347/203 (C)'),\n",
    "(1, 347, '1000', 'BASIC', 5.04, -5.84, 4.50, 1.42, -4.50, -0.46, -0.88, '1/347/1000');\n",
    "\n",
    "-- You can add more rows following the same pattern for the rest of your data\n",
    "-- Note: Rows with N/A values should be excluded or handled with NULL values\n",
    "\n",
    "-- Create some useful views for analysis\n",
    "CREATE OR REPLACE VIEW STRESS_SUMMARY AS\n",
    "SELECT \n",
    "    MEMBER_ID,\n",
    "    NODE_ID,\n",
    "    CASE_TYPE,\n",
    "    MAX(S_MAX_MPA) as MAX_STRESS_MPA,\n",
    "    MIN(S_MIN_MPA) as MIN_STRESS_MPA,\n",
    "    AVG(ABS(S_MAX_MPA)) as AVG_ABS_MAX_STRESS,\n",
    "    COUNT(*) as NUM_CASES\n",
    "FROM DIM_STRUCTURAL_ANALYSIS \n",
    "WHERE S_MAX_MPA IS NOT NULL\n",
    "GROUP BY MEMBER_ID, NODE_ID, CASE_TYPE;\n",
    "\n",
    "CREATE OR REPLACE VIEW CRITICAL_STRESS_POINTS AS\n",
    "SELECT \n",
    "    MEMBER_NODE_CASE,\n",
    "    MEMBER_ID,\n",
    "    NODE_ID,\n",
    "    CASE_ID,\n",
    "    CASE_TYPE,\n",
    "    S_MAX_MPA,\n",
    "    S_MIN_MPA,\n",
    "    ABS(S_MAX_MPA) as ABS_MAX_STRESS,\n",
    "    ABS(S_MIN_MPA) as ABS_MIN_STRESS\n",
    "FROM DIM_STRUCTURAL_ANALYSIS \n",
    "WHERE ABS(S_MAX_MPA) > 10 OR ABS(S_MIN_MPA) > 10\n",
    "ORDER BY ABS_MAX_STRESS DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc088cde-eff3-47cb-b98d-921d79b3d4cc",
   "metadata": {
    "collapsed": false,
    "name": "Cortex_Analyst"
   },
   "source": [
    "### Semantic Models\n",
    "\n",
    "The semantic model maps business terminology to the structured data and adds contextual meaning. It allows Cortex Analyst to generate the correct SQL for a question asked in natural language.\n",
    "\n",
    "NOTE: To explore semantic models, refer to these [instructions](https://github.com/Snowflake-Labs/sfguide-build-data-agents-using-snowflake-cortex-ai?tab=readme-ov-file#step-5-explore-the-semantic-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121f643-d9b7-4784-a50f-83edfa02ddce",
   "metadata": {
    "language": "sql",
    "name": "Copy_semantic_model"
   },
   "outputs": [],
   "source": [
    "create or replace stage semantic_files ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = ( ENABLE = true );\n",
    "#changed database with my own\n",
    "COPY FILES\n",
    "    INTO @semantic_files/\n",
    "    FROM @SOPHIE_CORTEX_AGENTS_SUMMIT.PUBLIC.git_repo/branches/main/\n",
    "    FILES = ('semantic.yaml', 'semantic_search.yaml');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09d287-24c7-4691-ab2b-4a7a29f523e7",
   "metadata": {
    "collapsed": false,
    "name": "Dynamic_literal_retrieval"
   },
   "source": [
    "### Improve Tool Usage with Dynamic Literal Retrieval\n",
    "\n",
    "Using Cortex Analyst integration with Cortex Search, we can improve the retrieval of possible values of a column without listing them all in the semantic model file. \n",
    "\n",
    "Let's try it as example for the ARTICLE NAMES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313c2a7-09d6-4850-8318-80dca424ffab",
   "metadata": {
    "language": "sql",
    "name": "Create_new_service"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE CORTEX SEARCH SERVICE _ARTICLE_NAME_SEARCH\n",
    "  ON ARTICLE_NAME\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "      DISTINCT ARTICLE_NAME\n",
    "  FROM DIM_ARTICLE\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424016df-dbd4-4f05-92f4-b4ba393ee02b",
   "metadata": {
    "collapsed": false,
    "name": "Continuation"
   },
   "source": [
    "### *NOTE: This concludes the setup tools portion of this guide. Follow [instructions outlined here](https://quickstarts.snowflake.com/guide/build-agentic-application-in-snowflake/index.html?index=..%2F..index#3) to proceed to next steps.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  },
  "lastEditStatus": {
   "authorEmail": "iamontheinet@gmail.com",
   "authorId": "8359025379711",
   "authorName": "DASH",
   "lastEditTime": 1750905228647,
   "notebookId": "vqpltujytisuqo6adonf",
   "sessionId": "9458f325-0fac-4f75-8b3f-a2a14c00987e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
